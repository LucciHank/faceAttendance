{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## install & import c√°c th∆∞ vi·ªán"
      ],
      "metadata": {
        "id": "TsWYIkxW0NTi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ktKLtd9WPJKD"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics tensorflow scikit-learn pillow\n",
        "!pip install -q supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaO5RkJOGpV_",
        "outputId": "6e3fbd76-04d7-4a47-9788-c8d8cd18081b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-17 08:58:18--  https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12x.pt\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/38c16fee-f912-46d3-a455-b442e265c41b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250317T085818Z&X-Amz-Expires=300&X-Amz-Signature=58c5e2191358659d5f6e39502ad121b6bc317bbeb0863e7816bf344f468a3959&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolo12x.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-17 08:58:18--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/38c16fee-f912-46d3-a455-b442e265c41b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250317%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250317T085818Z&X-Amz-Expires=300&X-Amz-Signature=58c5e2191358659d5f6e39502ad121b6bc317bbeb0863e7816bf344f468a3959&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolo12x.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 119322638 (114M) [application/octet-stream]\n",
            "Saving to: ‚Äòyolo12x.pt.2‚Äô\n",
            "\n",
            "yolo12x.pt.2        100%[===================>] 113.79M  59.0MB/s    in 1.9s    \n",
            "\n",
            "2025-03-17 08:58:21 (59.0 MB/s) - ‚Äòyolo12x.pt.2‚Äô saved [119322638/119322638]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12x.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "s11p0D4e95AU"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade ultralytics\n",
        "!pip install -q --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "hQDMRaCjPPNE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from torchvision import models, transforms\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmSgkbAXLcE5",
        "outputId": "4f697bec-9f71-4a54-8035-2b2bad201ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### S·ª≠ d·ª•ng YOLO12 nh·∫≠n di·ªán g∆∞∆°ng m·∫∑t, Resnet ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng, SCV ƒë·ªÉ ph√¢n lo·∫°i"
      ],
      "metadata": {
        "id": "R7w30nTr0urx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UjTMKosARxg",
        "outputId": "919a3fc9-c05b-4e64-f6df-83aa49236cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 1\n",
            "üé• X·ª≠ l√Ω video: A.mov\n",
            "\n",
            "0: 448x640 2 persons, 63.9ms\n",
            "Speed: 2.9ms preprocess, 63.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 53.2ms\n",
            "Speed: 4.2ms preprocess, 53.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 47.7ms\n",
            "Speed: 4.1ms preprocess, 47.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 46.3ms\n",
            "Speed: 3.8ms preprocess, 46.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 51.2ms\n",
            "Speed: 10.6ms preprocess, 51.2ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 56.0ms\n",
            "Speed: 4.1ms preprocess, 56.0ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 46.3ms\n",
            "Speed: 3.9ms preprocess, 46.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 69.3ms\n",
            "Speed: 4.6ms preprocess, 69.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 48.4ms\n",
            "Speed: 8.2ms preprocess, 48.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 55.7ms\n",
            "Speed: 3.9ms preprocess, 55.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 52.0ms\n",
            "Speed: 9.2ms preprocess, 52.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 46.2ms\n",
            "Speed: 3.8ms preprocess, 46.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 43.4ms\n",
            "Speed: 7.3ms preprocess, 43.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 43.5ms\n",
            "Speed: 4.2ms preprocess, 43.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 43.7ms\n",
            "Speed: 5.0ms preprocess, 43.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 42.7ms\n",
            "Speed: 4.5ms preprocess, 42.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 66.9ms\n",
            "Speed: 4.7ms preprocess, 66.9ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 51.3ms\n",
            "Speed: 4.0ms preprocess, 51.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 47.3ms\n",
            "Speed: 4.0ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 95.2ms\n",
            "Speed: 8.2ms preprocess, 95.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 48.2ms\n",
            "Speed: 6.1ms preprocess, 48.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 74.0ms\n",
            "Speed: 4.8ms preprocess, 74.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 51.1ms\n",
            "Speed: 5.4ms preprocess, 51.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 60.0ms\n",
            "Speed: 7.3ms preprocess, 60.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 48.3ms\n",
            "Speed: 4.0ms preprocess, 48.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 46.6ms\n",
            "Speed: 4.2ms preprocess, 46.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 47.0ms\n",
            "Speed: 4.7ms preprocess, 47.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 76.5ms\n",
            "Speed: 7.8ms preprocess, 76.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 64.3ms\n",
            "Speed: 4.5ms preprocess, 64.3ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 48.9ms\n",
            "Speed: 11.7ms preprocess, 48.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 149.2ms\n",
            "Speed: 5.7ms preprocess, 149.2ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 81.2ms\n",
            "Speed: 4.5ms preprocess, 81.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 129.0ms\n",
            "Speed: 20.9ms preprocess, 129.0ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 100.6ms\n",
            "Speed: 3.9ms preprocess, 100.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 51.3ms\n",
            "Speed: 6.2ms preprocess, 51.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 107.6ms\n",
            "Speed: 8.2ms preprocess, 107.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 95.5ms\n",
            "Speed: 12.5ms preprocess, 95.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 209.3ms\n",
            "Speed: 17.9ms preprocess, 209.3ms inference, 9.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 168.1ms\n",
            "Speed: 3.9ms preprocess, 168.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 76.0ms\n",
            "Speed: 4.0ms preprocess, 76.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 125.8ms\n",
            "Speed: 11.4ms preprocess, 125.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 99.9ms\n",
            "Speed: 12.6ms preprocess, 99.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 186.6ms\n",
            "Speed: 12.1ms preprocess, 186.6ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 101.0ms\n",
            "Speed: 13.2ms preprocess, 101.0ms inference, 9.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 83.6ms\n",
            "Speed: 17.6ms preprocess, 83.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 100.2ms\n",
            "Speed: 4.1ms preprocess, 100.2ms inference, 10.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 123.6ms\n",
            "Speed: 9.3ms preprocess, 123.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 2\n",
            "üé• X·ª≠ l√Ω video: d349d8615a3a476bbb6ee1f975424d9a.mov\n",
            "\n",
            "0: 640x480 1 person, 92.3ms\n",
            "Speed: 3.8ms preprocess, 92.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 78.1ms\n",
            "Speed: 3.5ms preprocess, 78.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 84.4ms\n",
            "Speed: 3.5ms preprocess, 84.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 66.6ms\n",
            "Speed: 3.6ms preprocess, 66.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 81.8ms\n",
            "Speed: 5.3ms preprocess, 81.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 75.1ms\n",
            "Speed: 2.9ms preprocess, 75.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 68.3ms\n",
            "Speed: 5.5ms preprocess, 68.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 47.8ms\n",
            "Speed: 2.8ms preprocess, 47.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 70.2ms\n",
            "Speed: 4.9ms preprocess, 70.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 65.9ms\n",
            "Speed: 9.8ms preprocess, 65.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 47.1ms\n",
            "Speed: 3.1ms preprocess, 47.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 57.4ms\n",
            "Speed: 3.6ms preprocess, 57.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 84.8ms\n",
            "Speed: 4.2ms preprocess, 84.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 47.1ms\n",
            "Speed: 3.5ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 48.9ms\n",
            "Speed: 3.7ms preprocess, 48.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 59.8ms\n",
            "Speed: 3.6ms preprocess, 59.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 51.2ms\n",
            "Speed: 6.8ms preprocess, 51.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 67.8ms\n",
            "Speed: 3.6ms preprocess, 67.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 73.6ms\n",
            "Speed: 3.6ms preprocess, 73.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 71.3ms\n",
            "Speed: 3.9ms preprocess, 71.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 147.6ms\n",
            "Speed: 3.9ms preprocess, 147.6ms inference, 12.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 59.5ms\n",
            "Speed: 8.1ms preprocess, 59.5ms inference, 11.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 61.8ms\n",
            "Speed: 8.6ms preprocess, 61.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 62.5ms\n",
            "Speed: 3.6ms preprocess, 62.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 54.4ms\n",
            "Speed: 9.9ms preprocess, 54.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 49.7ms\n",
            "Speed: 3.5ms preprocess, 49.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 49.0ms\n",
            "Speed: 3.5ms preprocess, 49.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 48.4ms\n",
            "Speed: 3.5ms preprocess, 48.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 50.3ms\n",
            "Speed: 3.6ms preprocess, 50.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 51.0ms\n",
            "Speed: 3.5ms preprocess, 51.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 48.7ms\n",
            "Speed: 3.5ms preprocess, 48.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 76.9ms\n",
            "Speed: 3.4ms preprocess, 76.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 55.1ms\n",
            "Speed: 5.6ms preprocess, 55.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 119.0ms\n",
            "Speed: 3.4ms preprocess, 119.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 53.7ms\n",
            "Speed: 3.4ms preprocess, 53.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 51.7ms\n",
            "Speed: 4.5ms preprocess, 51.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 87.2ms\n",
            "Speed: 3.4ms preprocess, 87.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 68.7ms\n",
            "Speed: 5.3ms preprocess, 68.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 50.1ms\n",
            "Speed: 3.5ms preprocess, 50.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 62.8ms\n",
            "Speed: 9.7ms preprocess, 62.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 61.4ms\n",
            "Speed: 3.4ms preprocess, 61.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 53.3ms\n",
            "Speed: 2.9ms preprocess, 53.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 56.9ms\n",
            "Speed: 3.3ms preprocess, 56.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 62.7ms\n",
            "Speed: 3.2ms preprocess, 62.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 88.0ms\n",
            "Speed: 3.7ms preprocess, 88.0ms inference, 6.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 74.2ms\n",
            "Speed: 9.7ms preprocess, 74.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 85.9ms\n",
            "Speed: 3.5ms preprocess, 85.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 96.2ms\n",
            "Speed: 3.6ms preprocess, 96.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 80.8ms\n",
            "Speed: 3.5ms preprocess, 80.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 104.7ms\n",
            "Speed: 6.5ms preprocess, 104.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 82.9ms\n",
            "Speed: 3.5ms preprocess, 82.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 48.5ms\n",
            "Speed: 3.5ms preprocess, 48.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 115.5ms\n",
            "Speed: 3.5ms preprocess, 115.5ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 1 chair, 50.9ms\n",
            "Speed: 3.5ms preprocess, 50.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 53.2ms\n",
            "Speed: 6.3ms preprocess, 53.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 97.0ms\n",
            "Speed: 9.1ms preprocess, 97.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 57.0ms\n",
            "Speed: 3.5ms preprocess, 57.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 48.1ms\n",
            "Speed: 3.4ms preprocess, 48.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 89.7ms\n",
            "Speed: 6.5ms preprocess, 89.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 47.0ms\n",
            "Speed: 3.4ms preprocess, 47.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 49.8ms\n",
            "Speed: 13.0ms preprocess, 49.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 52.1ms\n",
            "Speed: 3.3ms preprocess, 52.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 49.9ms\n",
            "Speed: 3.4ms preprocess, 49.9ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 51.1ms\n",
            "Speed: 3.5ms preprocess, 51.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 62.6ms\n",
            "Speed: 3.4ms preprocess, 62.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 113.2ms\n",
            "Speed: 3.4ms preprocess, 113.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 62.5ms\n",
            "Speed: 4.2ms preprocess, 62.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 59.0ms\n",
            "Speed: 3.4ms preprocess, 59.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 53.1ms\n",
            "Speed: 3.1ms preprocess, 53.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 66.6ms\n",
            "Speed: 4.1ms preprocess, 66.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 46.9ms\n",
            "Speed: 4.4ms preprocess, 46.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 52.1ms\n",
            "Speed: 4.4ms preprocess, 52.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 83.9ms\n",
            "Speed: 4.1ms preprocess, 83.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 63.9ms\n",
            "Speed: 7.5ms preprocess, 63.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 53.1ms\n",
            "Speed: 11.8ms preprocess, 53.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 59.7ms\n",
            "Speed: 3.5ms preprocess, 59.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 112.7ms\n",
            "Speed: 6.2ms preprocess, 112.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 57.2ms\n",
            "Speed: 3.8ms preprocess, 57.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 74.3ms\n",
            "Speed: 6.3ms preprocess, 74.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 53.3ms\n",
            "Speed: 3.4ms preprocess, 53.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 107.2ms\n",
            "Speed: 3.6ms preprocess, 107.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 60.1ms\n",
            "Speed: 3.7ms preprocess, 60.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 49.8ms\n",
            "Speed: 3.6ms preprocess, 49.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 50.4ms\n",
            "Speed: 3.8ms preprocess, 50.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 person, 69.7ms\n",
            "Speed: 4.0ms preprocess, 69.7ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 6\n",
            "üé• X·ª≠ l√Ω video: HieÃÇÃÅu.mov\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 2 tvs, 138.4ms\n",
            "Speed: 4.1ms preprocess, 138.4ms inference, 9.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 81.2ms\n",
            "Speed: 4.0ms preprocess, 81.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 hair drier, 148.2ms\n",
            "Speed: 3.9ms preprocess, 148.2ms inference, 17.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 108.7ms\n",
            "Speed: 13.7ms preprocess, 108.7ms inference, 7.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 67.1ms\n",
            "Speed: 11.0ms preprocess, 67.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 63.5ms\n",
            "Speed: 7.9ms preprocess, 63.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 101.4ms\n",
            "Speed: 3.9ms preprocess, 101.4ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 1 keyboard, 166.7ms\n",
            "Speed: 16.8ms preprocess, 166.7ms inference, 9.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 1 keyboard, 110.8ms\n",
            "Speed: 6.9ms preprocess, 110.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 196.3ms\n",
            "Speed: 16.1ms preprocess, 196.3ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 104.1ms\n",
            "Speed: 4.1ms preprocess, 104.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 165.0ms\n",
            "Speed: 4.2ms preprocess, 165.0ms inference, 23.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 156.2ms\n",
            "Speed: 4.0ms preprocess, 156.2ms inference, 9.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 keyboard, 190.5ms\n",
            "Speed: 8.9ms preprocess, 190.5ms inference, 7.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 159.5ms\n",
            "Speed: 5.6ms preprocess, 159.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 148.1ms\n",
            "Speed: 4.2ms preprocess, 148.1ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 keyboard, 174.0ms\n",
            "Speed: 9.0ms preprocess, 174.0ms inference, 8.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 134.5ms\n",
            "Speed: 28.1ms preprocess, 134.5ms inference, 13.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 123.9ms\n",
            "Speed: 10.6ms preprocess, 123.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 82.3ms\n",
            "Speed: 3.8ms preprocess, 82.3ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 83.7ms\n",
            "Speed: 4.3ms preprocess, 83.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 69.9ms\n",
            "Speed: 5.3ms preprocess, 69.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 90.7ms\n",
            "Speed: 3.9ms preprocess, 90.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 61.7ms\n",
            "Speed: 7.6ms preprocess, 61.7ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 90.8ms\n",
            "Speed: 4.0ms preprocess, 90.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 72.2ms\n",
            "Speed: 3.9ms preprocess, 72.2ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 62.6ms\n",
            "Speed: 6.1ms preprocess, 62.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 62.7ms\n",
            "Speed: 3.8ms preprocess, 62.7ms inference, 22.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 72.1ms\n",
            "Speed: 4.6ms preprocess, 72.1ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 1 laptop, 123.6ms\n",
            "Speed: 9.4ms preprocess, 123.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 1 laptop, 88.1ms\n",
            "Speed: 4.0ms preprocess, 88.1ms inference, 2.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 72.1ms\n",
            "Speed: 4.0ms preprocess, 72.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 72.1ms\n",
            "Speed: 5.3ms preprocess, 72.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 laptop, 66.7ms\n",
            "Speed: 4.0ms preprocess, 66.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 laptop, 66.3ms\n",
            "Speed: 4.3ms preprocess, 66.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 laptop, 47.4ms\n",
            "Speed: 3.7ms preprocess, 47.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 1 laptop, 47.5ms\n",
            "Speed: 4.0ms preprocess, 47.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 44.6ms\n",
            "Speed: 3.7ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 1 cell phone, 44.5ms\n",
            "Speed: 3.9ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 cell phone, 44.5ms\n",
            "Speed: 3.7ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 cell phone, 44.6ms\n",
            "Speed: 3.8ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 cell phone, 44.5ms\n",
            "Speed: 3.9ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 44.0ms\n",
            "Speed: 4.1ms preprocess, 44.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 44.3ms\n",
            "Speed: 4.0ms preprocess, 44.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 44.1ms\n",
            "Speed: 3.8ms preprocess, 44.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 1 cell phone, 44.2ms\n",
            "Speed: 5.7ms preprocess, 44.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 43.6ms\n",
            "Speed: 4.0ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.4ms\n",
            "Speed: 3.7ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.2ms\n",
            "Speed: 4.2ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.1ms\n",
            "Speed: 4.4ms preprocess, 44.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.2ms\n",
            "Speed: 4.3ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 3 tvs, 43.9ms\n",
            "Speed: 3.8ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 43.6ms\n",
            "Speed: 3.5ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 43.7ms\n",
            "Speed: 4.1ms preprocess, 43.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 44.3ms\n",
            "Speed: 4.0ms preprocess, 44.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 3 tvs, 44.2ms\n",
            "Speed: 3.9ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 3 tvs, 44.5ms\n",
            "Speed: 2.8ms preprocess, 44.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 2 tvs, 44.8ms\n",
            "Speed: 3.8ms preprocess, 44.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 2 tvs, 1 cell phone, 44.5ms\n",
            "Speed: 4.3ms preprocess, 44.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 2 tvs, 1 cell phone, 47.0ms\n",
            "Speed: 5.3ms preprocess, 47.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 3 tvs, 44.5ms\n",
            "Speed: 4.2ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 44.1ms\n",
            "Speed: 4.1ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 44.0ms\n",
            "Speed: 3.9ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 44.7ms\n",
            "Speed: 5.6ms preprocess, 44.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 44.5ms\n",
            "Speed: 3.7ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 43.9ms\n",
            "Speed: 4.0ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 2 tvs, 43.3ms\n",
            "Speed: 3.5ms preprocess, 43.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 car, 1 chair, 2 tvs, 45.5ms\n",
            "Speed: 4.2ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 45.0ms\n",
            "Speed: 3.7ms preprocess, 45.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 43.6ms\n",
            "Speed: 4.3ms preprocess, 43.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 45.1ms\n",
            "Speed: 4.2ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 44.3ms\n",
            "Speed: 3.4ms preprocess, 44.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 44.5ms\n",
            "Speed: 3.9ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 2 tvs, 44.8ms\n",
            "Speed: 3.6ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 44.8ms\n",
            "Speed: 4.4ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 43.5ms\n",
            "Speed: 3.4ms preprocess, 43.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 5\n",
            "üé• X·ª≠ l√Ω video: HaÃ£nh.mov\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.3ms\n",
            "Speed: 6.7ms preprocess, 44.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.9ms\n",
            "Speed: 3.0ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.6ms\n",
            "Speed: 4.0ms preprocess, 44.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.0ms\n",
            "Speed: 3.4ms preprocess, 44.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.0ms\n",
            "Speed: 4.4ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 45.0ms\n",
            "Speed: 3.7ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.5ms\n",
            "Speed: 4.1ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.3ms\n",
            "Speed: 3.8ms preprocess, 43.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 1 cell phone, 42.9ms\n",
            "Speed: 3.9ms preprocess, 42.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.5ms\n",
            "Speed: 5.8ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.1ms\n",
            "Speed: 4.0ms preprocess, 44.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.5ms\n",
            "Speed: 4.0ms preprocess, 44.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.3ms\n",
            "Speed: 5.1ms preprocess, 43.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.3ms\n",
            "Speed: 3.9ms preprocess, 43.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.9ms\n",
            "Speed: 3.8ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 45.3ms\n",
            "Speed: 5.9ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.8ms\n",
            "Speed: 5.9ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 60.6ms\n",
            "Speed: 4.1ms preprocess, 60.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.6ms\n",
            "Speed: 3.9ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.4ms\n",
            "Speed: 4.3ms preprocess, 44.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.8ms\n",
            "Speed: 4.0ms preprocess, 43.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.4ms\n",
            "Speed: 4.5ms preprocess, 43.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.5ms\n",
            "Speed: 4.3ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.5ms\n",
            "Speed: 3.8ms preprocess, 44.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.0ms\n",
            "Speed: 5.7ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.0ms\n",
            "Speed: 4.2ms preprocess, 44.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.6ms\n",
            "Speed: 4.4ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 47.7ms\n",
            "Speed: 9.8ms preprocess, 47.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 47.5ms\n",
            "Speed: 5.7ms preprocess, 47.5ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 56.1ms\n",
            "Speed: 5.3ms preprocess, 56.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 55.3ms\n",
            "Speed: 8.7ms preprocess, 55.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 59.2ms\n",
            "Speed: 4.7ms preprocess, 59.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 55.4ms\n",
            "Speed: 6.6ms preprocess, 55.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.5ms\n",
            "Speed: 3.9ms preprocess, 44.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.4ms\n",
            "Speed: 4.0ms preprocess, 43.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 48.4ms\n",
            "Speed: 3.9ms preprocess, 48.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 52.7ms\n",
            "Speed: 5.7ms preprocess, 52.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 48.6ms\n",
            "Speed: 4.0ms preprocess, 48.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 46.3ms\n",
            "Speed: 7.1ms preprocess, 46.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 44.9ms\n",
            "Speed: 3.8ms preprocess, 44.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 55.4ms\n",
            "Speed: 3.7ms preprocess, 55.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 umbrella, 43.4ms\n",
            "Speed: 3.9ms preprocess, 43.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 4\n",
            "üé• X·ª≠ l√Ω video: Giang.mov\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 44.2ms\n",
            "Speed: 5.9ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 56.3ms\n",
            "Speed: 3.9ms preprocess, 56.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 52.4ms\n",
            "Speed: 7.7ms preprocess, 52.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 45.8ms\n",
            "Speed: 3.9ms preprocess, 45.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 54.0ms\n",
            "Speed: 3.9ms preprocess, 54.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 55.0ms\n",
            "Speed: 7.0ms preprocess, 55.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 44.2ms\n",
            "Speed: 11.7ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 44.6ms\n",
            "Speed: 6.3ms preprocess, 44.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 3 tvs, 2 keyboards, 55.6ms\n",
            "Speed: 3.8ms preprocess, 55.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 72.6ms\n",
            "Speed: 3.9ms preprocess, 72.6ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 1 keyboard, 50.7ms\n",
            "Speed: 5.0ms preprocess, 50.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 1 keyboard, 47.0ms\n",
            "Speed: 4.8ms preprocess, 47.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 keyboard, 43.7ms\n",
            "Speed: 4.6ms preprocess, 43.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 2 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 4.9ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 keyboard, 44.2ms\n",
            "Speed: 4.0ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 1 keyboard, 45.2ms\n",
            "Speed: 5.2ms preprocess, 45.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 keyboard, 44.0ms\n",
            "Speed: 4.4ms preprocess, 44.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 1 keyboard, 43.9ms\n",
            "Speed: 4.1ms preprocess, 43.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 5.4ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 3.9ms preprocess, 45.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 mouse, 1 keyboard, 44.6ms\n",
            "Speed: 6.2ms preprocess, 44.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 3.9ms preprocess, 44.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 keyboard, 44.2ms\n",
            "Speed: 3.7ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 3 tvs, 1 keyboard, 44.4ms\n",
            "Speed: 3.7ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 mouse, 1 keyboard, 45.0ms\n",
            "Speed: 4.3ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 3 chairs, 3 tvs, 1 keyboard, 45.2ms\n",
            "Speed: 4.1ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 keyboard, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 3 tvs, 1 keyboard, 44.6ms\n",
            "Speed: 4.8ms preprocess, 44.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 keyboard, 44.6ms\n",
            "Speed: 3.8ms preprocess, 44.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 4.4ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 keyboard, 44.9ms\n",
            "Speed: 3.9ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 4 tvs, 1 keyboard, 45.4ms\n",
            "Speed: 6.3ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 4 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 44.4ms\n",
            "Speed: 3.9ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 2 keyboards, 44.5ms\n",
            "Speed: 5.3ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 mouse, 2 keyboards, 44.6ms\n",
            "Speed: 4.0ms preprocess, 44.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 mouse, 1 keyboard, 44.9ms\n",
            "Speed: 3.2ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 mouse, 1 keyboard, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 4 tvs, 1 mouse, 1 keyboard, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 2 tvs, 1 mouse, 1 keyboard, 45.7ms\n",
            "Speed: 2.8ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 1 mouse, 1 keyboard, 44.6ms\n",
            "Speed: 4.1ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 2 tvs, 1 mouse, 2 keyboards, 45.1ms\n",
            "Speed: 4.4ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 2 tvs, 1 mouse, 2 keyboards, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 2 tvs, 1 mouse, 2 keyboards, 44.0ms\n",
            "Speed: 4.1ms preprocess, 44.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 2 tvs, 1 mouse, 2 keyboards, 45.6ms\n",
            "Speed: 4.1ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 mouse, 2 keyboards, 45.6ms\n",
            "Speed: 3.9ms preprocess, 45.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 3 tvs, 1 mouse, 2 keyboards, 44.7ms\n",
            "Speed: 3.9ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 4 tvs, 1 mouse, 2 keyboards, 44.4ms\n",
            "Speed: 4.8ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 mouse, 2 keyboards, 44.5ms\n",
            "Speed: 5.7ms preprocess, 44.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 3 tvs, 1 mouse, 2 keyboards, 45.7ms\n",
            "Speed: 6.2ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 3 tvs, 1 mouse, 2 keyboards, 44.8ms\n",
            "Speed: 8.6ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 3 tvs, 1 mouse, 2 keyboards, 44.6ms\n",
            "Speed: 5.8ms preprocess, 44.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 3 tvs, 1 mouse, 1 keyboard, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 2 tvs, 1 mouse, 1 keyboard, 44.9ms\n",
            "Speed: 3.7ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 4 tvs, 1 mouse, 1 keyboard, 44.6ms\n",
            "Speed: 3.7ms preprocess, 44.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 mouse, 1 keyboard, 44.6ms\n",
            "Speed: 3.9ms preprocess, 44.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 mouse, 1 keyboard, 44.3ms\n",
            "Speed: 4.0ms preprocess, 44.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 2 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 4.2ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 2 keyboards, 45.3ms\n",
            "Speed: 4.9ms preprocess, 45.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 1 keyboard, 45.7ms\n",
            "Speed: 7.4ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 5.1ms preprocess, 44.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 4.3ms preprocess, 44.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 3\n",
            "üé• X·ª≠ l√Ω video: ƒêaÃ£t.mov\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 44.7ms\n",
            "Speed: 4.3ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 43.7ms\n",
            "Speed: 4.1ms preprocess, 43.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 44.4ms\n",
            "Speed: 3.8ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 45.0ms\n",
            "Speed: 3.9ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 45.4ms\n",
            "Speed: 4.1ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 45.2ms\n",
            "Speed: 4.1ms preprocess, 45.2ms inference, 2.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 45.9ms\n",
            "Speed: 4.5ms preprocess, 45.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 44.4ms\n",
            "Speed: 3.9ms preprocess, 44.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 45.1ms\n",
            "Speed: 3.8ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 43.9ms\n",
            "Speed: 4.3ms preprocess, 43.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 43.8ms\n",
            "Speed: 4.0ms preprocess, 43.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 43.6ms\n",
            "Speed: 4.1ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 44.3ms\n",
            "Speed: 4.0ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 43.1ms\n",
            "Speed: 4.0ms preprocess, 43.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 43.7ms\n",
            "Speed: 4.0ms preprocess, 43.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 43.5ms\n",
            "Speed: 4.1ms preprocess, 43.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 50.9ms\n",
            "Speed: 6.5ms preprocess, 50.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 3 tvs, 45.2ms\n",
            "Speed: 4.5ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 43.6ms\n",
            "Speed: 4.0ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 42.1ms\n",
            "Speed: 4.2ms preprocess, 42.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 45.6ms\n",
            "Speed: 3.9ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 3.5ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 47.1ms\n",
            "Speed: 2.6ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 45.7ms\n",
            "Speed: 4.1ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 4.4ms preprocess, 45.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 44.5ms\n",
            "Speed: 4.0ms preprocess, 44.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 46.1ms\n",
            "Speed: 4.1ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 2 tvs, 1 keyboard, 46.7ms\n",
            "Speed: 4.4ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 2 tvs, 1 keyboard, 46.2ms\n",
            "Speed: 3.8ms preprocess, 46.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 2 tvs, 44.3ms\n",
            "Speed: 3.9ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 44.7ms\n",
            "Speed: 3.9ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 2 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 4.2ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 3 tvs, 45.4ms\n",
            "Speed: 3.8ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 45.2ms\n",
            "Speed: 5.2ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 46.2ms\n",
            "Speed: 5.4ms preprocess, 46.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 46.1ms\n",
            "Speed: 4.0ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 44.0ms\n",
            "Speed: 4.4ms preprocess, 44.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 chairs, 3 tvs, 1 keyboard, 43.9ms\n",
            "Speed: 3.9ms preprocess, 43.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 6.6ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 1 keyboard, 45.4ms\n",
            "Speed: 4.1ms preprocess, 45.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 2 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 3.9ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 1 keyboard, 44.4ms\n",
            "Speed: 3.9ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 3.9ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 4.7ms preprocess, 45.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 2 chairs, 3 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 5.1ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 2 chairs, 3 tvs, 1 keyboard, 52.8ms\n",
            "Speed: 6.0ms preprocess, 52.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 9\n",
            "üé• X·ª≠ l√Ω video: Nam.mov\n",
            "\n",
            "0: 448x640 5 persons, 3 chairs, 2 tvs, 2 keyboards, 45.0ms\n",
            "Speed: 6.0ms preprocess, 45.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 2 keyboards, 46.0ms\n",
            "Speed: 3.8ms preprocess, 46.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 3 keyboards, 52.7ms\n",
            "Speed: 3.9ms preprocess, 52.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 2 keyboards, 46.0ms\n",
            "Speed: 3.9ms preprocess, 46.0ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 48.8ms\n",
            "Speed: 7.6ms preprocess, 48.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 2 keyboards, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 54.1ms\n",
            "Speed: 5.0ms preprocess, 54.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 48.3ms\n",
            "Speed: 4.0ms preprocess, 48.3ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 45.6ms\n",
            "Speed: 4.1ms preprocess, 45.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 53.0ms\n",
            "Speed: 4.1ms preprocess, 53.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 45.2ms\n",
            "Speed: 4.1ms preprocess, 45.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 45.5ms\n",
            "Speed: 9.6ms preprocess, 45.5ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 55.0ms\n",
            "Speed: 12.1ms preprocess, 55.0ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 44.2ms\n",
            "Speed: 3.9ms preprocess, 44.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 3 tvs, 2 keyboards, 65.6ms\n",
            "Speed: 5.8ms preprocess, 65.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.5ms\n",
            "Speed: 4.2ms preprocess, 44.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 55.7ms\n",
            "Speed: 11.8ms preprocess, 55.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 56.9ms\n",
            "Speed: 3.3ms preprocess, 56.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 58.2ms\n",
            "Speed: 6.0ms preprocess, 58.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 51.8ms\n",
            "Speed: 11.9ms preprocess, 51.8ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 46.8ms\n",
            "Speed: 3.9ms preprocess, 46.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 52.0ms\n",
            "Speed: 7.6ms preprocess, 52.0ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 59.4ms\n",
            "Speed: 4.4ms preprocess, 59.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 50.9ms\n",
            "Speed: 3.9ms preprocess, 50.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 56.7ms\n",
            "Speed: 12.4ms preprocess, 56.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.9ms\n",
            "Speed: 3.7ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 47.3ms\n",
            "Speed: 9.0ms preprocess, 47.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.9ms\n",
            "Speed: 4.1ms preprocess, 45.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 43.8ms\n",
            "Speed: 6.1ms preprocess, 43.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 46.4ms\n",
            "Speed: 4.1ms preprocess, 46.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 46.1ms\n",
            "Speed: 3.8ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.6ms\n",
            "Speed: 9.0ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.7ms\n",
            "Speed: 5.5ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 46.0ms\n",
            "Speed: 7.1ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 4.2ms preprocess, 44.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.3ms\n",
            "Speed: 3.9ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.3ms\n",
            "Speed: 2.9ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 47.1ms\n",
            "Speed: 3.0ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 48.1ms\n",
            "Speed: 6.8ms preprocess, 48.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 47.4ms\n",
            "Speed: 3.8ms preprocess, 47.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 46.1ms\n",
            "Speed: 4.1ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.8ms\n",
            "Speed: 6.2ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.9ms\n",
            "Speed: 3.7ms preprocess, 45.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.5ms\n",
            "Speed: 5.1ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 2 keyboards, 45.8ms\n",
            "Speed: 3.6ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.4ms\n",
            "Speed: 4.1ms preprocess, 44.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.8ms\n",
            "Speed: 4.0ms preprocess, 45.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.4ms\n",
            "Speed: 4.1ms preprocess, 45.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.3ms\n",
            "Speed: 4.0ms preprocess, 44.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.6ms\n",
            "Speed: 3.9ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 5.5ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 49.0ms\n",
            "Speed: 13.4ms preprocess, 49.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.1ms\n",
            "Speed: 4.0ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 6.6ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 3 tvs, 1 keyboard, 44.9ms\n",
            "Speed: 3.8ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.4ms\n",
            "Speed: 6.6ms preprocess, 45.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 3 chairs, 2 tvs, 1 keyboard, 45.0ms\n",
            "Speed: 4.1ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.2ms\n",
            "Speed: 3.8ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 43.4ms\n",
            "Speed: 3.9ms preprocess, 43.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 7.4ms preprocess, 44.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.9ms\n",
            "Speed: 4.3ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.5ms\n",
            "Speed: 4.2ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.6ms\n",
            "Speed: 3.8ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 4.1ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 45.5ms\n",
            "Speed: 3.8ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 46.0ms\n",
            "Speed: 4.1ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 3 chairs, 2 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 5.6ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 4.2ms preprocess, 44.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.2ms\n",
            "Speed: 4.1ms preprocess, 44.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.7ms\n",
            "Speed: 3.9ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 4.2ms preprocess, 44.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.7ms\n",
            "Speed: 3.9ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.1ms\n",
            "Speed: 4.1ms preprocess, 44.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 44.8ms\n",
            "Speed: 4.0ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 3 chairs, 2 tvs, 1 keyboard, 45.9ms\n",
            "Speed: 3.8ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 8\n",
            "üé• X·ª≠ l√Ω video: Movie on 3-17-25 at 1.34‚ÄØPM.mov\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.7ms\n",
            "Speed: 4.5ms preprocess, 46.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 48.1ms\n",
            "Speed: 5.9ms preprocess, 48.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.7ms\n",
            "Speed: 3.5ms preprocess, 47.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 8.3ms preprocess, 45.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.4ms\n",
            "Speed: 3.9ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.7ms\n",
            "Speed: 3.2ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.4ms\n",
            "Speed: 3.9ms preprocess, 46.4ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.7ms\n",
            "Speed: 3.4ms preprocess, 46.7ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 48.2ms\n",
            "Speed: 4.0ms preprocess, 48.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.6ms\n",
            "Speed: 3.6ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.4ms\n",
            "Speed: 3.6ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 43.4ms\n",
            "Speed: 6.2ms preprocess, 43.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.0ms\n",
            "Speed: 3.9ms preprocess, 47.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 44.2ms\n",
            "Speed: 5.0ms preprocess, 44.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.5ms\n",
            "Speed: 3.8ms preprocess, 46.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.0ms\n",
            "Speed: 4.0ms preprocess, 47.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.9ms\n",
            "Speed: 3.9ms preprocess, 45.9ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.0ms\n",
            "Speed: 7.9ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 3.5ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.6ms\n",
            "Speed: 5.0ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.3ms\n",
            "Speed: 3.6ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.5ms\n",
            "Speed: 9.7ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.8ms\n",
            "Speed: 3.7ms preprocess, 45.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 44.4ms\n",
            "Speed: 3.8ms preprocess, 44.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.0ms\n",
            "Speed: 3.7ms preprocess, 47.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 3.2ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 4.0ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.5ms\n",
            "Speed: 3.8ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 5.7ms preprocess, 45.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.4ms\n",
            "Speed: 4.0ms preprocess, 46.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.2ms\n",
            "Speed: 3.8ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.1ms\n",
            "Speed: 3.6ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.5ms\n",
            "Speed: 4.0ms preprocess, 46.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.3ms\n",
            "Speed: 4.2ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.3ms\n",
            "Speed: 3.7ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.1ms\n",
            "Speed: 3.4ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.5ms\n",
            "Speed: 4.7ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.8ms\n",
            "Speed: 6.6ms preprocess, 45.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.5ms\n",
            "Speed: 6.7ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 6.1ms preprocess, 46.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 3.6ms preprocess, 46.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 4.7ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 8.3ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 4.0ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 44.7ms\n",
            "Speed: 5.1ms preprocess, 44.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.1ms\n",
            "Speed: 7.2ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.2ms\n",
            "Speed: 4.6ms preprocess, 46.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.9ms\n",
            "Speed: 3.7ms preprocess, 45.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.9ms\n",
            "Speed: 5.5ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 47.0ms\n",
            "Speed: 4.1ms preprocess, 47.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 46.2ms\n",
            "Speed: 3.2ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.0ms\n",
            "Speed: 4.2ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.0ms\n",
            "Speed: 4.2ms preprocess, 45.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 4.2ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.4ms\n",
            "Speed: 6.4ms preprocess, 45.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 56.6ms\n",
            "Speed: 5.2ms preprocess, 56.6ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 51.8ms\n",
            "Speed: 3.6ms preprocess, 51.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 7.3ms preprocess, 46.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.4ms\n",
            "Speed: 3.6ms preprocess, 47.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 49.6ms\n",
            "Speed: 3.9ms preprocess, 49.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.9ms\n",
            "Speed: 6.2ms preprocess, 46.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.5ms\n",
            "Speed: 3.6ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 48.6ms\n",
            "Speed: 4.7ms preprocess, 48.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 5.7ms preprocess, 46.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 52.4ms\n",
            "Speed: 3.5ms preprocess, 52.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 51.1ms\n",
            "Speed: 4.7ms preprocess, 51.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 54.4ms\n",
            "Speed: 3.6ms preprocess, 54.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.1ms\n",
            "Speed: 5.2ms preprocess, 47.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 48.3ms\n",
            "Speed: 4.6ms preprocess, 48.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 52.1ms\n",
            "Speed: 4.5ms preprocess, 52.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 50.7ms\n",
            "Speed: 6.9ms preprocess, 50.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.4ms\n",
            "Speed: 8.1ms preprocess, 47.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.1ms\n",
            "Speed: 3.6ms preprocess, 45.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 49.2ms\n",
            "Speed: 6.1ms preprocess, 49.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 44.5ms\n",
            "Speed: 3.6ms preprocess, 44.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 61.5ms\n",
            "Speed: 3.5ms preprocess, 61.5ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 55.1ms\n",
            "Speed: 3.8ms preprocess, 55.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.5ms\n",
            "Speed: 3.3ms preprocess, 45.5ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 59.6ms\n",
            "Speed: 3.6ms preprocess, 59.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üé• X·ª≠ l√Ω video: Movie on 3-17-25 at 1.33‚ÄØPM.mov\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.8ms\n",
            "Speed: 3.7ms preprocess, 44.8ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.9ms\n",
            "Speed: 3.7ms preprocess, 45.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 52.6ms\n",
            "Speed: 3.8ms preprocess, 52.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 57.6ms\n",
            "Speed: 3.6ms preprocess, 57.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 49.6ms\n",
            "Speed: 3.5ms preprocess, 49.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 57.6ms\n",
            "Speed: 3.6ms preprocess, 57.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 57.4ms\n",
            "Speed: 3.6ms preprocess, 57.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 51.4ms\n",
            "Speed: 3.9ms preprocess, 51.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 54.5ms\n",
            "Speed: 3.7ms preprocess, 54.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 52.6ms\n",
            "Speed: 7.1ms preprocess, 52.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 52.1ms\n",
            "Speed: 4.8ms preprocess, 52.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.2ms\n",
            "Speed: 5.4ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.7ms\n",
            "Speed: 5.3ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 44.8ms\n",
            "Speed: 2.8ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.0ms\n",
            "Speed: 4.0ms preprocess, 45.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.7ms\n",
            "Speed: 6.7ms preprocess, 44.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.1ms\n",
            "Speed: 3.7ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.6ms\n",
            "Speed: 3.6ms preprocess, 44.6ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.7ms\n",
            "Speed: 4.6ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 46.3ms\n",
            "Speed: 3.9ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 51.4ms\n",
            "Speed: 7.9ms preprocess, 51.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.4ms\n",
            "Speed: 6.7ms preprocess, 45.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.5ms\n",
            "Speed: 5.7ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.5ms\n",
            "Speed: 7.1ms preprocess, 44.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.1ms\n",
            "Speed: 3.6ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.6ms\n",
            "Speed: 3.8ms preprocess, 45.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.4ms\n",
            "Speed: 6.1ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.2ms\n",
            "Speed: 3.5ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.2ms\n",
            "Speed: 2.4ms preprocess, 45.2ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.8ms\n",
            "Speed: 3.5ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 43.9ms\n",
            "Speed: 4.1ms preprocess, 43.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 47.7ms\n",
            "Speed: 3.5ms preprocess, 47.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.2ms\n",
            "Speed: 8.5ms preprocess, 45.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.1ms\n",
            "Speed: 7.4ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 3.9ms preprocess, 45.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.2ms\n",
            "Speed: 4.0ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.8ms\n",
            "Speed: 6.6ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.6ms\n",
            "Speed: 4.9ms preprocess, 45.6ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.5ms\n",
            "Speed: 3.7ms preprocess, 46.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.1ms\n",
            "Speed: 4.3ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.8ms\n",
            "Speed: 7.6ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.0ms\n",
            "Speed: 5.6ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.6ms\n",
            "Speed: 3.8ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.1ms\n",
            "Speed: 2.6ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.1ms\n",
            "Speed: 3.6ms preprocess, 46.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.5ms\n",
            "Speed: 4.2ms preprocess, 44.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 potted plant, 1 vase, 45.6ms\n",
            "Speed: 3.7ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.5ms\n",
            "Speed: 5.0ms preprocess, 46.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 46.5ms\n",
            "Speed: 4.1ms preprocess, 46.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.3ms\n",
            "Speed: 3.9ms preprocess, 47.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 44.4ms\n",
            "Speed: 5.4ms preprocess, 44.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 1 vase, 45.7ms\n",
            "Speed: 3.7ms preprocess, 45.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.4ms\n",
            "Speed: 2.5ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.9ms\n",
            "Speed: 6.9ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 3.6ms preprocess, 45.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.2ms\n",
            "Speed: 3.6ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.3ms\n",
            "Speed: 4.6ms preprocess, 46.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.6ms\n",
            "Speed: 6.4ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.2ms\n",
            "Speed: 4.7ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 4.6ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.9ms\n",
            "Speed: 3.5ms preprocess, 46.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.1ms\n",
            "Speed: 3.7ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.6ms\n",
            "Speed: 4.4ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.1ms\n",
            "Speed: 3.5ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.4ms\n",
            "Speed: 4.5ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.0ms\n",
            "Speed: 8.6ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 45.7ms\n",
            "Speed: 4.3ms preprocess, 45.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.6ms\n",
            "Speed: 3.9ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.2ms\n",
            "Speed: 5.5ms preprocess, 46.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 44.8ms\n",
            "Speed: 8.3ms preprocess, 44.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 47.7ms\n",
            "Speed: 3.9ms preprocess, 47.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cup, 1 potted plant, 46.5ms\n",
            "Speed: 3.8ms preprocess, 46.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 7\n",
            "üé• X·ª≠ l√Ω video: Movie on 3-17-25 at 1.37‚ÄØPM.mov\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 44.6ms\n",
            "Speed: 3.9ms preprocess, 44.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 47.3ms\n",
            "Speed: 4.6ms preprocess, 47.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.7ms\n",
            "Speed: 4.0ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.7ms\n",
            "Speed: 4.0ms preprocess, 46.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.4ms\n",
            "Speed: 3.8ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 2 chairs, 1 potted plant, 46.4ms\n",
            "Speed: 3.9ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.1ms\n",
            "Speed: 3.7ms preprocess, 46.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.1ms\n",
            "Speed: 3.7ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 45.0ms\n",
            "Speed: 6.0ms preprocess, 45.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 44.6ms\n",
            "Speed: 6.2ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.4ms\n",
            "Speed: 3.2ms preprocess, 46.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.1ms\n",
            "Speed: 3.9ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.5ms\n",
            "Speed: 5.9ms preprocess, 46.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 1 potted plant, 46.3ms\n",
            "Speed: 3.9ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 45.1ms\n",
            "Speed: 4.6ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 45.9ms\n",
            "Speed: 4.0ms preprocess, 45.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 2 chairs, 45.7ms\n",
            "Speed: 4.0ms preprocess, 45.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 1 chair, 45.4ms\n",
            "Speed: 3.6ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 1 chair, 45.8ms\n",
            "Speed: 3.9ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 1 chair, 45.2ms\n",
            "Speed: 5.6ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 handbag, 1 chair, 45.0ms\n",
            "Speed: 7.5ms preprocess, 45.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.4ms\n",
            "Speed: 3.9ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 45.4ms\n",
            "Speed: 3.7ms preprocess, 45.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 46.4ms\n",
            "Speed: 3.9ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 47.4ms\n",
            "Speed: 3.8ms preprocess, 47.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.9ms\n",
            "Speed: 4.0ms preprocess, 46.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.7ms\n",
            "Speed: 3.6ms preprocess, 46.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.4ms\n",
            "Speed: 3.8ms preprocess, 46.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.6ms\n",
            "Speed: 3.6ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.2ms\n",
            "Speed: 3.7ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 45.6ms\n",
            "Speed: 4.4ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 47.0ms\n",
            "Speed: 5.3ms preprocess, 47.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 46.5ms\n",
            "Speed: 4.4ms preprocess, 46.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 1 potted plant, 45.7ms\n",
            "Speed: 5.2ms preprocess, 45.7ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 45.8ms\n",
            "Speed: 3.5ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.6ms\n",
            "Speed: 4.0ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 45.9ms\n",
            "Speed: 6.5ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 45.5ms\n",
            "Speed: 4.5ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.3ms\n",
            "Speed: 3.7ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 2 chairs, 46.0ms\n",
            "Speed: 4.7ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 46.6ms\n",
            "Speed: 4.2ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 46.4ms\n",
            "Speed: 7.8ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 45.7ms\n",
            "Speed: 4.4ms preprocess, 45.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 chair, 45.2ms\n",
            "Speed: 8.5ms preprocess, 45.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 carrot, 3 chairs, 45.4ms\n",
            "Speed: 3.9ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 handbags, 1 carrot, 3 chairs, 45.0ms\n",
            "Speed: 5.5ms preprocess, 45.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 46.2ms\n",
            "Speed: 5.2ms preprocess, 46.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 chairs, 48.1ms\n",
            "Speed: 3.8ms preprocess, 48.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üé• X·ª≠ l√Ω video: Ly.mov\n",
            "\n",
            "0: 448x640 1 person, 46.5ms\n",
            "Speed: 4.0ms preprocess, 46.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.4ms\n",
            "Speed: 4.2ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.9ms\n",
            "Speed: 4.3ms preprocess, 45.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.3ms\n",
            "Speed: 4.2ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.6ms\n",
            "Speed: 3.9ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.7ms\n",
            "Speed: 4.1ms preprocess, 45.7ms inference, 2.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 44.5ms\n",
            "Speed: 4.2ms preprocess, 44.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 53.7ms\n",
            "Speed: 6.6ms preprocess, 53.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 49.9ms\n",
            "Speed: 7.7ms preprocess, 49.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.6ms\n",
            "Speed: 3.8ms preprocess, 46.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.8ms\n",
            "Speed: 3.9ms preprocess, 45.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.2ms\n",
            "Speed: 5.2ms preprocess, 45.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 61.1ms\n",
            "Speed: 3.9ms preprocess, 61.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 48.4ms\n",
            "Speed: 8.3ms preprocess, 48.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 50.5ms\n",
            "Speed: 7.0ms preprocess, 50.5ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 53.0ms\n",
            "Speed: 6.9ms preprocess, 53.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 61.4ms\n",
            "Speed: 4.2ms preprocess, 61.4ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 51.1ms\n",
            "Speed: 3.8ms preprocess, 51.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.1ms\n",
            "Speed: 6.7ms preprocess, 46.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 59.4ms\n",
            "Speed: 6.6ms preprocess, 59.4ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 51.2ms\n",
            "Speed: 7.9ms preprocess, 51.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 60.8ms\n",
            "Speed: 3.8ms preprocess, 60.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 56.0ms\n",
            "Speed: 4.0ms preprocess, 56.0ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 44.6ms\n",
            "Speed: 4.7ms preprocess, 44.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 57.8ms\n",
            "Speed: 6.3ms preprocess, 57.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.0ms\n",
            "Speed: 6.0ms preprocess, 46.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 67.7ms\n",
            "Speed: 8.8ms preprocess, 67.7ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 65.2ms\n",
            "Speed: 6.9ms preprocess, 65.2ms inference, 2.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 49.1ms\n",
            "Speed: 4.5ms preprocess, 49.1ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 50.3ms\n",
            "Speed: 16.2ms preprocess, 50.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 52.1ms\n",
            "Speed: 3.9ms preprocess, 52.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 50.5ms\n",
            "Speed: 4.1ms preprocess, 50.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 51.0ms\n",
            "Speed: 4.3ms preprocess, 51.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.7ms\n",
            "Speed: 5.2ms preprocess, 47.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.2ms\n",
            "Speed: 7.3ms preprocess, 46.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.4ms\n",
            "Speed: 3.9ms preprocess, 46.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.0ms\n",
            "Speed: 7.3ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.3ms\n",
            "Speed: 4.4ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.0ms\n",
            "Speed: 4.0ms preprocess, 46.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.1ms\n",
            "Speed: 5.6ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.5ms\n",
            "Speed: 5.1ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.5ms\n",
            "Speed: 5.9ms preprocess, 46.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.2ms\n",
            "Speed: 6.3ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.3ms\n",
            "Speed: 4.0ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 48.9ms\n",
            "Speed: 3.7ms preprocess, 48.9ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.7ms\n",
            "Speed: 3.8ms preprocess, 47.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.1ms\n",
            "Speed: 3.9ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 43.6ms\n",
            "Speed: 3.8ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.1ms\n",
            "Speed: 3.9ms preprocess, 47.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.8ms\n",
            "Speed: 4.0ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.3ms\n",
            "Speed: 3.9ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.4ms\n",
            "Speed: 4.3ms preprocess, 47.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.2ms\n",
            "Speed: 3.0ms preprocess, 47.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.8ms\n",
            "Speed: 3.9ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cell phone, 47.4ms\n",
            "Speed: 4.3ms preprocess, 47.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 45.7ms\n",
            "Speed: 6.8ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cell phone, 44.9ms\n",
            "Speed: 4.1ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 cell phone, 45.9ms\n",
            "Speed: 6.5ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 44.2ms\n",
            "Speed: 4.0ms preprocess, 44.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 46.5ms\n",
            "Speed: 3.7ms preprocess, 46.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 47.2ms\n",
            "Speed: 8.9ms preprocess, 47.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 46.9ms\n",
            "Speed: 5.7ms preprocess, 46.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 47.4ms\n",
            "Speed: 4.2ms preprocess, 47.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 10\n",
            "üé• X·ª≠ l√Ω video: ThaÃÇÃÄy.mov\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 46.2ms\n",
            "Speed: 4.2ms preprocess, 46.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 47.1ms\n",
            "Speed: 4.4ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 46.6ms\n",
            "Speed: 7.8ms preprocess, 46.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 45.6ms\n",
            "Speed: 4.2ms preprocess, 45.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 45.3ms\n",
            "Speed: 3.9ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.6ms\n",
            "Speed: 7.4ms preprocess, 44.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 44.9ms\n",
            "Speed: 4.3ms preprocess, 44.9ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 46.2ms\n",
            "Speed: 3.9ms preprocess, 46.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 1 mouse, 46.6ms\n",
            "Speed: 4.1ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 47.3ms\n",
            "Speed: 4.0ms preprocess, 47.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 46.3ms\n",
            "Speed: 4.3ms preprocess, 46.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 46.4ms\n",
            "Speed: 3.6ms preprocess, 46.4ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 4.1ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 45.0ms\n",
            "Speed: 4.3ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 7 persons, 1 chair, 4 tvs, 44.1ms\n",
            "Speed: 4.0ms preprocess, 44.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 7 persons, 1 chair, 4 tvs, 44.6ms\n",
            "Speed: 4.4ms preprocess, 44.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 7 persons, 1 chair, 4 tvs, 45.1ms\n",
            "Speed: 4.2ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 7 persons, 1 chair, 4 tvs, 44.7ms\n",
            "Speed: 3.9ms preprocess, 44.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 43.6ms\n",
            "Speed: 4.5ms preprocess, 43.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 46.6ms\n",
            "Speed: 4.3ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 46.3ms\n",
            "Speed: 6.3ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 7 persons, 1 chair, 4 tvs, 47.1ms\n",
            "Speed: 9.4ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 47.1ms\n",
            "Speed: 4.7ms preprocess, 47.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 48.1ms\n",
            "Speed: 4.3ms preprocess, 48.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 48.9ms\n",
            "Speed: 9.9ms preprocess, 48.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 48.0ms\n",
            "Speed: 4.8ms preprocess, 48.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.9ms\n",
            "Speed: 4.1ms preprocess, 46.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.6ms\n",
            "Speed: 4.6ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.4ms\n",
            "Speed: 4.3ms preprocess, 45.4ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.5ms\n",
            "Speed: 3.9ms preprocess, 45.5ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 4.0ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.2ms\n",
            "Speed: 4.0ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 44.9ms\n",
            "Speed: 3.9ms preprocess, 44.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.2ms\n",
            "Speed: 3.9ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 46.3ms\n",
            "Speed: 2.5ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 45.9ms\n",
            "Speed: 4.6ms preprocess, 45.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 46.8ms\n",
            "Speed: 11.3ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 5 tvs, 45.3ms\n",
            "Speed: 4.1ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 5 tvs, 46.6ms\n",
            "Speed: 3.7ms preprocess, 46.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 4 tvs, 46.1ms\n",
            "Speed: 7.9ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 47.0ms\n",
            "Speed: 4.2ms preprocess, 47.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 49.1ms\n",
            "Speed: 4.2ms preprocess, 49.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 49.5ms\n",
            "Speed: 4.1ms preprocess, 49.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.8ms\n",
            "Speed: 9.6ms preprocess, 45.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 4.1ms preprocess, 45.7ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 45.6ms\n",
            "Speed: 4.0ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.8ms\n",
            "Speed: 4.0ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.8ms\n",
            "Speed: 4.1ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 3.9ms preprocess, 45.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 3.8ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.6ms\n",
            "Speed: 7.4ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.2ms\n",
            "Speed: 4.6ms preprocess, 45.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.3ms\n",
            "Speed: 4.1ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.9ms\n",
            "Speed: 3.9ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 46.4ms\n",
            "Speed: 4.9ms preprocess, 46.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.8ms\n",
            "Speed: 3.9ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.6ms\n",
            "Speed: 4.6ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.3ms\n",
            "Speed: 4.4ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.6ms\n",
            "Speed: 6.8ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.6ms\n",
            "Speed: 4.6ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.7ms\n",
            "Speed: 4.0ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.1ms\n",
            "Speed: 4.1ms preprocess, 45.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 50.3ms\n",
            "Speed: 4.2ms preprocess, 50.3ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 61.7ms\n",
            "Speed: 4.1ms preprocess, 61.7ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 46.2ms\n",
            "Speed: 5.3ms preprocess, 46.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.3ms\n",
            "Speed: 3.8ms preprocess, 45.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 45.2ms\n",
            "Speed: 4.4ms preprocess, 45.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 58.6ms\n",
            "Speed: 4.0ms preprocess, 58.6ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 11\n",
            "üé• X·ª≠ l√Ω video: Trang.mov\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 48.0ms\n",
            "Speed: 4.0ms preprocess, 48.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 47.3ms\n",
            "Speed: 4.2ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 45.1ms\n",
            "Speed: 4.0ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 49.3ms\n",
            "Speed: 4.0ms preprocess, 49.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 59.8ms\n",
            "Speed: 13.2ms preprocess, 59.8ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 61.8ms\n",
            "Speed: 10.7ms preprocess, 61.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 44.8ms\n",
            "Speed: 4.2ms preprocess, 44.8ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 57.5ms\n",
            "Speed: 8.4ms preprocess, 57.5ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 47.9ms\n",
            "Speed: 4.7ms preprocess, 47.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 5 tvs, 1 laptop, 55.2ms\n",
            "Speed: 4.2ms preprocess, 55.2ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 44.9ms\n",
            "Speed: 4.0ms preprocess, 44.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 44.6ms\n",
            "Speed: 4.9ms preprocess, 44.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 2 tvs, 1 laptop, 65.8ms\n",
            "Speed: 10.7ms preprocess, 65.8ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 46.2ms\n",
            "Speed: 4.5ms preprocess, 46.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 71.3ms\n",
            "Speed: 4.0ms preprocess, 71.3ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 46.5ms\n",
            "Speed: 3.9ms preprocess, 46.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 67.7ms\n",
            "Speed: 5.8ms preprocess, 67.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 57.2ms\n",
            "Speed: 10.2ms preprocess, 57.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 4 tvs, 1 laptop, 46.4ms\n",
            "Speed: 4.3ms preprocess, 46.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 46.8ms\n",
            "Speed: 4.1ms preprocess, 46.8ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 46.3ms\n",
            "Speed: 4.0ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 4 tvs, 1 laptop, 46.8ms\n",
            "Speed: 4.0ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 45.8ms\n",
            "Speed: 4.5ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 44.9ms\n",
            "Speed: 3.9ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 4 tvs, 1 laptop, 45.3ms\n",
            "Speed: 4.3ms preprocess, 45.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 45.6ms\n",
            "Speed: 5.5ms preprocess, 45.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 46.6ms\n",
            "Speed: 5.8ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 44.8ms\n",
            "Speed: 4.6ms preprocess, 44.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 48.8ms\n",
            "Speed: 9.5ms preprocess, 48.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 52.6ms\n",
            "Speed: 5.4ms preprocess, 52.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 47.7ms\n",
            "Speed: 4.4ms preprocess, 47.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 59.6ms\n",
            "Speed: 4.0ms preprocess, 59.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 46.6ms\n",
            "Speed: 4.4ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 45.1ms\n",
            "Speed: 3.9ms preprocess, 45.1ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 44.1ms\n",
            "Speed: 4.2ms preprocess, 44.1ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 45.6ms\n",
            "Speed: 5.2ms preprocess, 45.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 45.8ms\n",
            "Speed: 4.5ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 45.0ms\n",
            "Speed: 6.0ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 55.5ms\n",
            "Speed: 5.6ms preprocess, 55.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 4 tvs, 1 laptop, 44.5ms\n",
            "Speed: 4.5ms preprocess, 44.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 1 hair drier, 45.1ms\n",
            "Speed: 5.2ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 3 tvs, 1 laptop, 45.4ms\n",
            "Speed: 8.0ms preprocess, 45.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 45.2ms\n",
            "Speed: 4.6ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 1 chair, 3 tvs, 1 laptop, 46.1ms\n",
            "Speed: 4.0ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 45.5ms\n",
            "Speed: 4.6ms preprocess, 45.5ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 45.3ms\n",
            "Speed: 4.0ms preprocess, 45.3ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 46.4ms\n",
            "Speed: 4.2ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 44.9ms\n",
            "Speed: 6.0ms preprocess, 44.9ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 46.5ms\n",
            "Speed: 8.5ms preprocess, 46.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 5 persons, 1 chair, 4 tvs, 1 laptop, 44.9ms\n",
            "Speed: 3.8ms preprocess, 44.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 3 tvs, 1 laptop, 45.0ms\n",
            "Speed: 8.5ms preprocess, 45.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 4 persons, 1 chair, 4 tvs, 1 laptop, 45.9ms\n",
            "Speed: 4.8ms preprocess, 45.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 3 tvs, 1 laptop, 44.4ms\n",
            "Speed: 4.3ms preprocess, 44.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 6 persons, 1 chair, 2 tvs, 1 laptop, 45.8ms\n",
            "Speed: 4.4ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "üìÇ ƒêang x·ª≠ l√Ω nh√¢n vi√™n: 12\n",
            "üé• X·ª≠ l√Ω video: VieÃ£ÃÇt.mov\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 2 tvs, 46.8ms\n",
            "Speed: 4.2ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 2 tvs, 46.9ms\n",
            "Speed: 4.7ms preprocess, 46.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 1 laptop, 43.1ms\n",
            "Speed: 9.5ms preprocess, 43.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 1 laptop, 47.1ms\n",
            "Speed: 7.2ms preprocess, 47.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 1 laptop, 46.3ms\n",
            "Speed: 7.6ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 48.6ms\n",
            "Speed: 5.9ms preprocess, 48.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 1 laptop, 48.7ms\n",
            "Speed: 5.6ms preprocess, 48.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 53.2ms\n",
            "Speed: 5.0ms preprocess, 53.2ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 3 chairs, 1 tv, 1 laptop, 46.4ms\n",
            "Speed: 4.6ms preprocess, 46.4ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 1 tv, 1 laptop, 46.1ms\n",
            "Speed: 4.3ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 2 tvs, 45.8ms\n",
            "Speed: 4.1ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 chairs, 1 tv, 1 laptop, 44.8ms\n",
            "Speed: 7.7ms preprocess, 44.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 2 tvs, 46.6ms\n",
            "Speed: 4.2ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 chair, 2 tvs, 45.1ms\n",
            "Speed: 5.2ms preprocess, 45.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 47.2ms\n",
            "Speed: 4.6ms preprocess, 47.2ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 1 laptop, 47.6ms\n",
            "Speed: 4.8ms preprocess, 47.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 tvs, 47.6ms\n",
            "Speed: 4.8ms preprocess, 47.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 1 laptop, 47.6ms\n",
            "Speed: 4.1ms preprocess, 47.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 1 laptop, 46.1ms\n",
            "Speed: 3.9ms preprocess, 46.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 45.6ms\n",
            "Speed: 4.1ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 45.8ms\n",
            "Speed: 4.6ms preprocess, 45.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 45.2ms\n",
            "Speed: 4.3ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 46.7ms\n",
            "Speed: 4.5ms preprocess, 46.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 47.4ms\n",
            "Speed: 3.8ms preprocess, 47.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 1 tv, 46.3ms\n",
            "Speed: 4.6ms preprocess, 46.3ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 tvs, 46.6ms\n",
            "Speed: 7.5ms preprocess, 46.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 3 tvs, 45.9ms\n",
            "Speed: 4.5ms preprocess, 45.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 1 person, 2 tvs, 46.0ms\n",
            "Speed: 4.2ms preprocess, 46.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 46.3ms\n",
            "Speed: 3.8ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 3 tvs, 45.6ms\n",
            "Speed: 14.5ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 45.6ms\n",
            "Speed: 4.4ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 45.9ms\n",
            "Speed: 6.3ms preprocess, 45.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 46.0ms\n",
            "Speed: 4.7ms preprocess, 46.0ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 45.7ms\n",
            "Speed: 4.0ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 46.1ms\n",
            "Speed: 8.0ms preprocess, 46.1ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 46.8ms\n",
            "Speed: 4.4ms preprocess, 46.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 1 chair, 2 tvs, 47.0ms\n",
            "Speed: 3.9ms preprocess, 47.0ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 1 laptop, 45.7ms\n",
            "Speed: 4.7ms preprocess, 45.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 3 tvs, 46.3ms\n",
            "Speed: 4.5ms preprocess, 46.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 2 persons, 2 tvs, 45.5ms\n",
            "Speed: 4.1ms preprocess, 45.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 tvs, 46.6ms\n",
            "Speed: 4.7ms preprocess, 46.6ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 448x640 3 persons, 2 tvs, 45.2ms\n",
            "Speed: 6.4ms preprocess, 45.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "‚úÖ Ho√†n t·∫•t tr√≠ch xu·∫•t ·∫£nh t·ª´ video!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "from glob import glob\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "\n",
        "# Load m√¥ h√¨nh YOLOv12\n",
        "model = YOLO('/content/yolo12x.pt')\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a c√°c folder nh√¢n vi√™n\n",
        "video_root = \"/content/drive/MyDrive/DeepLearning/data_cv\"\n",
        "output_folder = \"face_dataset\"\n",
        "\n",
        "# Duy·ªát t·ª´ng folder nh√¢n vi√™n trong th∆∞ m·ª•c g·ªëc\n",
        "for employee_folder in os.listdir(video_root):\n",
        "    employee_path = os.path.join(video_root, employee_folder)\n",
        "\n",
        "    # N·∫øu kh√¥ng ph·∫£i folder, b·ªè qua\n",
        "    if not os.path.isdir(employee_path):\n",
        "        continue\n",
        "\n",
        "    print(f\"ƒêang x·ª≠ l√Ω nh√¢n vi√™n: {employee_folder}\")\n",
        "\n",
        "    # Duy·ªát t·ª´ng video trong folder nh√¢n vi√™n\n",
        "    for video_name in os.listdir(employee_path):\n",
        "        video_path = os.path.join(employee_path, video_name)\n",
        "        if not video_name.lower().endswith(('.mp4', '.mov', '.avi', '.mkv')):\n",
        "            continue\n",
        "\n",
        "        print(f\"X·ª≠ l√Ω video: {video_name}\")\n",
        "\n",
        "        # M·ªü video\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_count, save_count = 0, 0\n",
        "\n",
        "        save_path = os.path.join(output_folder, employee_folder)\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            if frame_count % 5 == 0:\n",
        "                results = model(frame)\n",
        "\n",
        "                for result in results:\n",
        "                  # L·∫•y ID l·ªõp\n",
        "                    for box, cls in zip(result.boxes.xyxy, result.boxes.cls):\n",
        "                        class_id = int(cls)\n",
        "                        # Ch·ªâ l·∫•y khu√¥n m·∫∑t\n",
        "                        if class_id == 0:\n",
        "                            x1, y1, x2, y2 = map(int, box[:4])\n",
        "                            face = frame[y1:y2, x1:x2]\n",
        "\n",
        "                            if face.shape[0] > 0 and face.shape[1] > 0:\n",
        "                                face = cv2.resize(face, (100, 100))\n",
        "                                cv2.imwrite(f\"{save_path}/{save_count}.jpg\", face)\n",
        "                                save_count += 1\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "print(\"Ho√†n t·∫•t tr√≠ch xu·∫•t ·∫£nh t·ª´ video!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sgkj8toCAXvP",
        "outputId": "656dc88b-f753-4787-898b-928b52b7e5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu!\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "# H√†m ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
        "def preprocess_faces(data_path=\"face_dataset\"):\n",
        "    for folder in glob(f\"{data_path}/*\"):\n",
        "        for img_path in glob(f\"{folder}/*.jpg\"):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # ·∫¢nh x√°m\n",
        "            img = cv2.resize(img, (100, 100))  # Resize\n",
        "            cv2.imwrite(img_path, img)\n",
        "\n",
        "preprocess_faces()\n",
        "print(\"Ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5biKnqBEUxN",
        "outputId": "f4b7a2cf-e3fe-4449-bbb2-b2842561d36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load m√¥ h√¨nh ResNet50\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval()\n",
        "\n",
        "# Transform cho ·∫£nh\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def extract_features(image):\n",
        "    \"\"\" Nh·∫≠n ·∫£nh NumPy array ho·∫∑c ƒë∆∞·ªùng d·∫´n ·∫£nh \"\"\"\n",
        "    if isinstance(image, str):\n",
        "        image = cv2.imread(image)\n",
        "        if image is None:\n",
        "            print(f\"L·ªñI: Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh {image}\")\n",
        "            return None\n",
        "\n",
        "    if image is None or image.shape[0] == 0 or image.shape[1] == 0:\n",
        "        print(\"L·ªñI: ·∫¢nh kh√¥ng h·ª£p l·ªá!\")\n",
        "        return None\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = Image.fromarray(image)\n",
        "    image = transform(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
        "        feature = resnet(image).flatten().numpy()\n",
        "\n",
        "    return feature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEglrEvhAY__",
        "outputId": "d7a4929a-a2c6-4c96-a018-f70d6f946d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9752066115702479\n",
            "Confusion Matrix:\n",
            " [[19  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 66  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0 36  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 10  0  0  1  0  1  0  0  0]\n",
            " [ 0  0  0  0 17  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  0 34  0  0  0  0  0  0]\n",
            " [ 0  1  1  0  0  0 17  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  9  0  0  0  0]\n",
            " [ 0  0  1  0  0  1  0  0 66  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 14  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 16  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0 50]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        19\n",
            "          10       0.96      1.00      0.98        66\n",
            "          11       0.95      1.00      0.97        36\n",
            "          12       1.00      0.83      0.91        12\n",
            "           2       1.00      1.00      1.00        17\n",
            "           3       0.97      0.94      0.96        36\n",
            "           4       0.94      0.89      0.92        19\n",
            "           5       1.00      1.00      1.00         9\n",
            "           6       0.97      0.97      0.97        68\n",
            "           7       1.00      1.00      1.00        14\n",
            "           8       1.00      1.00      1.00        16\n",
            "           9       1.00      0.98      0.99        51\n",
            "\n",
            "    accuracy                           0.98       363\n",
            "   macro avg       0.98      0.97      0.97       363\n",
            "weighted avg       0.98      0.98      0.97       363\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "#l∆∞u c√°c ƒë·∫∑c tr∆∞ng v√†o file csv\n",
        "csv_data = []\n",
        "feature_columns = [f\"feature_{i+1}\" for i in range(2048)]\n",
        "X_train, y_train, X_test, y_test = [], [], [], []\n",
        "\n",
        "for folder in glob(\"face_dataset/*\"):\n",
        "    employee_id = os.path.basename(folder)\n",
        "    img_paths = glob(f\"{folder}/*.jpg\")\n",
        "    np.random.shuffle(img_paths)\n",
        " # chia ·∫£nh v√†o c√°c t·∫≠p train-test v·ªõi t·ªâ l·ªá 80% train, 20% test\n",
        "    split_idx = int(0.8 * len(img_paths))\n",
        "    train_paths, test_paths = img_paths[:split_idx], img_paths[split_idx:]\n",
        "\n",
        "    for img_path in train_paths:\n",
        "        feature = extract_features(img_path)\n",
        "        if feature is not None:\n",
        "            X_train.append(feature)\n",
        "            y_train.append(employee_id)\n",
        "            csv_data.append([employee_id, \"train\"] + feature.tolist())\n",
        "\n",
        "    for img_path in test_paths:\n",
        "        feature = extract_features(img_path)\n",
        "        if feature is not None:\n",
        "            X_test.append(feature)\n",
        "            y_test.append(employee_id)\n",
        "            csv_data.append([employee_id, \"test\"] + feature.tolist())\n",
        "\n",
        "# L∆∞u ƒë·∫∑c tr∆∞ng v√†o file CSV\n",
        "df = pd.DataFrame(csv_data, columns=[\"employee_id\", \"split\"] + feature_columns)\n",
        "df.to_csv(\"face_features.csv\", index=False)\n",
        "\n",
        "# Chuy·ªÉn th√†nh numpy array\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "# Hu·∫•n luy·ªán SVM\n",
        "clf = SVC(kernel=\"linear\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# D·ª± ƒëo√°n tr√™n t·∫≠p test\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# ƒê√°nh gi√° hi·ªáu su·∫•t\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPjQY1jcXzqw",
        "outputId": "1e981991-9540-4277-9523-8e81713d6acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ƒê√£ hu·∫•n luy·ªán xong v√† l∆∞u m√¥ h√¨nh!\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(clf, \"face_recognition_svm.pkl\")\n",
        "print(\"ƒê√£ hu·∫•n luy·ªán xong v√† l∆∞u m√¥ h√¨nh!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### S·ª≠ d·ª•ng mediapipe facemesh, facenet v√† svm"
      ],
      "metadata": {
        "id": "SSvbNx4H1i6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe"
      ],
      "metadata": {
        "id": "VGf_Uir896cZ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q onnxruntime"
      ],
      "metadata": {
        "id": "l3B502Zj-N92"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mediapipe as mp\n",
        "import onnxruntime as ort"
      ],
      "metadata": {
        "id": "CAYiTucy9mLm"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "# t·∫£i m√¥ h√¨nh\n",
        "url = \"https://thanglongedu-my.sharepoint.com/:u:/g/personal/a44212_thanglong_edu_vn/Ef3sjhgaRKNFqOrzTAi7ZgcBmef8hzm37GGOTTAZsuFTlw?download=1\"\n",
        "\n",
        "if not os.path.exists(\"face_recognition.onnx\"):\n",
        "    print(\"File ONNX ch∆∞a t·ªìn t·∫°i, ƒëang t·∫£i v·ªÅ...\")\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        with open(\"face_recognition.onnx\", \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(\"T·∫£i file th√†nh c√¥ng!\")\n",
        "    else:\n",
        "        print(f\"Kh√¥ng th·ªÉ t·∫£i file, m√£ l·ªói {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "it6-Seax_K5v"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_size(model_path):\n",
        "    \"\"\" Tr·∫£ v·ªÅ k√≠ch th∆∞·ªõc m√¥ h√¨nh (MB) \"\"\"\n",
        "    size = os.path.getsize(model_path) / (1024 * 1024)\n",
        "    return round(size, 2)\n"
      ],
      "metadata": {
        "id": "jmNav6GsAA-p"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "#nh·∫≠n di·ªán g∆∞∆°ng m·∫∑t\n",
        "def extract_faces_from_video(video_path, output_folder):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
        "    frame_count, save_count = 0, 0\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        if frame_count % 5 == 0:\n",
        "            img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            results = face_mesh.process(img_rgb)\n",
        "          # l·∫•y ra landmark t·ª´ g∆∞∆°ng m·∫∑t\n",
        "            if results.multi_face_landmarks:\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                    h, w, _ = frame.shape\n",
        "                    x_min = max(0, min([int(p.x * w) for p in face_landmarks.landmark]))\n",
        "                    y_min = max(0, min([int(p.y * h) for p in face_landmarks.landmark]))\n",
        "                    x_max = min(w, max([int(p.x * w) for p in face_landmarks.landmark]))\n",
        "                    y_max = min(h, max([int(p.y * h) for p in face_landmarks.landmark]))\n",
        "\n",
        "                    face = frame[y_min:y_max, x_min:x_max]\n",
        "                    if face.shape[0] > 0 and face.shape[1] > 0:\n",
        "                        face = cv2.resize(face, (160, 160))\n",
        "                        if len(face.shape) == 2:\n",
        "                            face = cv2.cvtColor(face, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "                        cv2.imwrite(f\"{output_folder}/{save_count}.jpg\", face)\n",
        "                        save_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Tr√≠ch xu·∫•t {save_count} ·∫£nh t·ª´ {video_path}\")\n"
      ],
      "metadata": {
        "id": "k6HP4Hry9VEI"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facenet_model = ort.InferenceSession(\"face_recognition.onnx\")\n",
        "# tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
        "def extract_features(img):\n",
        "    if img.shape != (160, 160, 3):\n",
        "        print(f\"·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: {img.shape}, b·ªè qua...\")\n",
        "        return None\n",
        "\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    img = np.transpose(img, (2, 0, 1))  # ƒê∆∞a v·ªÅ (C, H, W)\n",
        "    face_input = np.expand_dims(img, axis=0)\n",
        "\n",
        "    output = facenet_model.run(None, {facenet_model.get_inputs()[0].name: face_input})\n",
        "    return output[0][0] if output else None\n"
      ],
      "metadata": {
        "id": "w7ZAcOorD4E2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# h√†m hu·∫•n luy·ªán svm\n",
        "def train_svm(face_folder, labels):\n",
        "    X, y = [], []\n",
        "    for label, folder in enumerate(os.listdir(face_folder)):\n",
        "        folder_path = os.path.join(face_folder, folder)\n",
        "        if not os.path.isdir(folder_path):\n",
        "            continue\n",
        "\n",
        "        for img_name in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            feature = extract_features(img)\n",
        "            if feature is not None:\n",
        "                X.append(feature)\n",
        "                y.append(label)  # S·ª≠ d·ª•ng index thay v√¨ t√™n ƒë·ªÉ tr√°nh l·ªói\n",
        "\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"Kh√¥ng c√≥ d·ªØ li·ªáu hu·∫•n luy·ªán!\")\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    print(\"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán:\", X.shape)\n",
        "\n",
        "    svc = SVC(kernel=\"linear\", probability=True)\n",
        "    svc.fit(X, y)\n",
        "    joblib.dump(svc, \"facenet_svc.pkl\")\n",
        "    print(\" Hu·∫•n luy·ªán SVM ho√†n t·∫•t!\")\n"
      ],
      "metadata": {
        "id": "-sx8_F4XD5AT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_root = \"/content/drive/MyDrive/DeepLearning/data_cv\"\n",
        "face_dataset = \"face_dataset\"\n",
        "labels = []\n",
        "\n",
        "for emp_folder in os.listdir(video_root):\n",
        "    emp_path = os.path.join(video_root, emp_folder)\n",
        "    if os.path.isdir(emp_path):\n",
        "        labels.append(emp_folder)\n",
        "        output_path = os.path.join(face_dataset, emp_folder)\n",
        "        for video_name in os.listdir(emp_path):\n",
        "            if video_name.endswith(('.mp4', '.mov')):\n",
        "                extract_faces_from_video(os.path.join(emp_path, video_name), output_path)\n",
        "\n",
        "train_svm(face_dataset, labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydl8g5TTD_N4",
        "outputId": "7adcb3df-2368-490d-de68-83c56ce20f79"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tr√≠ch xu·∫•t 48 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/1/A.mov\n",
            "Tr√≠ch xu·∫•t 85 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/2/d349d8615a3a476bbb6ee1f975424d9a.mov\n",
            "Tr√≠ch xu·∫•t 73 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/6/HieÃÇÃÅu.mov\n",
            "Tr√≠ch xu·∫•t 36 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/5/HaÃ£nh.mov\n",
            "Tr√≠ch xu·∫•t 58 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/4/Giang.mov\n",
            "Tr√≠ch xu·∫•t 45 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/3/ƒêaÃ£t.mov\n",
            "Tr√≠ch xu·∫•t 77 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/9/Nam.mov\n",
            "Tr√≠ch xu·∫•t 80 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/8/Movie on 3-17-25 at 1.34‚ÄØPM.mov\n",
            "Tr√≠ch xu·∫•t 72 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/8/Movie on 3-17-25 at 1.33‚ÄØPM.mov\n",
            "Tr√≠ch xu·∫•t 48 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/7/Movie on 3-17-25 at 1.37‚ÄØPM.mov\n",
            "Tr√≠ch xu·∫•t 63 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/7/Ly.mov\n",
            "Tr√≠ch xu·∫•t 68 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/10/ThaÃÇÃÄy.mov\n",
            "Tr√≠ch xu·∫•t 54 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/11/Trang.mov\n",
            "Tr√≠ch xu·∫•t 42 ·∫£nh t·ª´ /content/drive/MyDrive/DeepLearning/data_cv/12/VieÃ£ÃÇt.mov\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "·∫¢nh c√≥ k√≠ch th∆∞·ªõc kh√¥ng h·ª£p l·ªá: (100, 100, 3), b·ªè qua...\n",
            "S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: (729, 512)\n",
            " Hu·∫•n luy·ªán SVM ho√†n t·∫•t!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import onnxruntime as ort\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load m√¥ h√¨nh ƒë√£ train\n",
        "svc = joblib.load(\"facenet_svc.pkl\")\n",
        "facenet_model = ort.InferenceSession(\"face_recognition.onnx\")\n",
        "\n",
        "def extract_features(img):\n",
        "    if img.shape != (160, 160, 3):\n",
        "        return None\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    img = np.transpose(img, (2, 0, 1))\n",
        "    face_input = np.expand_dims(img, axis=0)\n",
        "    output = facenet_model.run(None, {facenet_model.get_inputs()[0].name: face_input})\n",
        "    return output[0][0] if output else None\n",
        "\n",
        "# Load t·∫≠p test\n",
        "X_test, y_test = [], []\n",
        "test_folder = \"face_dataset_test\"\n",
        "\n",
        "for label, folder in enumerate(os.listdir(test_folder)):\n",
        "    folder_path = os.path.join(test_folder, folder)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        feature = extract_features(img)\n",
        "        if feature is not None:\n",
        "            X_test.append(feature)\n",
        "            y_test.append(label)\n",
        "\n",
        "# D·ª± ƒëo√°n tr√™n t·∫≠p test\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# In b√°o c√°o Precision, Recall, F1-score\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - FaceNet + SVM\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "rY0us3dcbnIG",
        "outputId": "0c09ba7e-7daa-46e3-9fa7-3dada0344b26"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Accuracy: 1.0000\n",
            "üìä Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       1.00      1.00      1.00        15\n",
            "           3       1.00      1.00      1.00        11\n",
            "           4       1.00      1.00      1.00         7\n",
            "           5       1.00      1.00      1.00        14\n",
            "           6       1.00      1.00      1.00        14\n",
            "           7       1.00      1.00      1.00        12\n",
            "           8       1.00      1.00      1.00        17\n",
            "           9       1.00      1.00      1.00        10\n",
            "          10       1.00      1.00      1.00        10\n",
            "          11       1.00      1.00      1.00        17\n",
            "\n",
            "    accuracy                           1.00       153\n",
            "   macro avg       1.00      1.00      1.00       153\n",
            "weighted avg       1.00      1.00      1.00       153\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgSY87MQAn-5",
        "outputId": "d82ddfec-f268-47c0-8911-cc8879e290ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# ƒê∆∞·ªùng d·∫´n video\n",
        "video_path = \"/content/a1c0eeec4f334873a9645ffdae336cac.mov\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# L∆∞u k·∫øt qu·∫£ nh·∫≠n di·ªán\n",
        "results_log = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # D·ª´ng n·∫øu h·∫øt video\n",
        "\n",
        "    # D√πng YOLO ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t\n",
        "    results = model(frame)\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            face = frame[y1:y2, x1:x2]  # C·∫Øt ·∫£nh khu√¥n m·∫∑t\n",
        "\n",
        "            if face.shape[0] > 0 and face.shape[1] > 0:\n",
        "                feature = extract_features(face)  # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
        "                if feature is not None:\n",
        "                    pred_id = clf.predict([feature])[0]  # D·ª± ƒëo√°n ID nh√¢n vi√™n\n",
        "\n",
        "                    # L∆∞u k·∫øt qu·∫£ v√†o danh s√°ch\n",
        "                    results_log.append(pred_id)\n",
        "\n",
        "                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ nh·∫≠n di·ªán tr√™n frame\n",
        "                    cv2.putText(frame, f\"ID: {pred_id}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Nh·∫•n \"q\" ƒë·ªÉ tho√°t\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# In k·∫øt qu·∫£ nh·∫≠n di·ªán cu·ªëi c√πng\n",
        "if results_log:\n",
        "    print(\"K·∫øt qu·∫£ nh·∫≠n di·ªán trong video:\")\n",
        "    unique_ids = set(results_log)\n",
        "    for emp_id in unique_ids:\n",
        "        print(f\" - Nh√¢n vi√™n ID: {emp_id} xu·∫•t hi·ªán {results_log.count(emp_id)} l·∫ßn\")\n",
        "else:\n",
        "    print(\"Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t n√†o!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "xxaVtqERX6Tp"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)  # M·ªü camera\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = yolo_model(frame)  # Ph√°t hi·ªán khu√¥n m·∫∑t\n",
        "\n",
        "    for result in results:\n",
        "        for box in result.boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box[:4])  # L·∫•y t·ªça ƒë·ªô\n",
        "            face = frame[y1:y2, x1:x2]  # C·∫Øt v√πng khu√¥n m·∫∑t\n",
        "\n",
        "            if face.shape[0] > 0 and face.shape[1] > 0:\n",
        "                feature = extract_features(face)  # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng\n",
        "                pred_id = clf.predict([feature])[0]  # D·ª± ƒëo√°n ID\n",
        "\n",
        "                cv2.putText(frame, f\"ID: {pred_id}\", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "\n",
        "    cv2.imshow(\"Face Recognition\", frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}